<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ü§ñ AI Assistant - Multi-Agent Chatbot</title>
    
    <!-- Include pako library for compression -->
    <script src="https://cdn.jsdelivr.net/npm/pako@2.1.0/dist/pako.min.js"></script>
    
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: #f5f7fa;
            min-height: 100vh;
            padding: 20px;
        }

        .app-container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 12px;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.08);
            overflow: hidden;
            border: 1px solid #e5e7eb;
        }

        .header {
            background: #1f2937;
            color: white;
            padding: 20px 30px;
            text-align: center;
        }

        .header h1 {
            font-size: 2.5rem;
            margin-bottom: 10px;
        }

        .header p {
            font-size: 1.1rem;
            opacity: 0.9;
        }

        .main-content {
            display: flex;
            height: 70vh;
        }

        .sidebar {
            width: 350px;
            background: #f9fafb;
            border-right: 1px solid #e5e7eb;
            display: flex;
            flex-direction: column;
        }

        .chat-area {
            flex: 1;
            display: flex;
            flex-direction: column;
            background: white;
        }

        /* Sidebar Styles */
        .agent-selector {
            padding: 20px;
            border-bottom: 1px solid #e5e7eb;
        }

        .agent-selector h3 {
            margin-bottom: 15px;
            color: #374151;
        }

        .agent-option {
            display: block;
            width: 100%;
            padding: 12px 15px;
            margin: 5px 0;
            border: 1px solid #d1d5db;
            border-radius: 8px;
            background: white;
            cursor: pointer;
            transition: all 0.3s ease;
            text-align: left;
        }

        .agent-option:hover {
            border-color: #6b7280;
            background: #f9fafb;
        }

        .agent-option.active {
            border-color: #374151;
            background: #374151;
            color: white;
        }

        .agent-option .agent-name {
            font-weight: bold;
            display: block;
        }

        .agent-option .agent-desc {
            font-size: 0.9rem;
            opacity: 0.8;
            margin-top: 5px;
        }

        .agent-option .message-count {
            display: inline-block;
            background: #6b7280;
            color: white;
            font-size: 0.75rem;
            padding: 2px 6px;
            border-radius: 10px;
            margin-left: 5px;
            min-width: 16px;
            text-align: center;
        }

        .agent-option.active .message-count {
            background: rgba(255, 255, 255, 0.3);
        }

        .document-upload {
            padding: 20px;
            border-bottom: 1px solid #e5e7eb;
        }

        .speech-status {
            padding: 20px;
        }


        .upload-area {
            border: 2px dashed #d1d5db;
            border-radius: 8px;
            padding: 20px;
            text-align: center;
            cursor: pointer;
            transition: all 0.3s ease;
            margin-top: 10px;
        }

        .upload-area:hover {
            border-color: #6b7280;
            background: #f9fafb;
        }

        .upload-area.dragover {
            border-color: #10b981;
            background: #f0fdf4;
        }

        /* Select dropdown styling */
        select {
            padding: 12px 15px;
            border-radius: 8px;
            border: 1px solid #d1d5db;
            margin: 5px 0;
            font-family: inherit;
            font-size: 14px;
            background: white;
            cursor: pointer;
            transition: all 0.3s ease;
            width: 100%;
        }

        select:hover {
            border-color: #6b7280;
            background: #f9fafb;
        }

        select:focus {
            outline: none;
            border-color: #374151;
            background: #f9fafb;
        }

        /* Chat Area Styles */
        .chat-header {
            padding: 20px 30px;
            background: #f9fafb;
            border-bottom: 1px solid #e5e7eb;
            display: flex;
            justify-content: between;
            align-items: center;
        }

        .chat-messages {
            flex: 1;
            overflow-y: auto;
            padding: 20px 30px;
            display: flex;
            flex-direction: column;
            gap: 15px;
        }

        .message {
            max-width: 80%;
            padding: 15px 20px;
            border-radius: 20px;
            word-wrap: break-word;
        }

        .message.user {
            align-self: flex-end;
            background: #374151;
            color: white;
            border-bottom-right-radius: 5px;
        }

        .message.assistant {
            align-self: flex-start;
            background: #f9fafb;
            border: 1px solid #e5e7eb;
            border-bottom-left-radius: 5px;
        }

        .message.system {
            align-self: center;
            background: #f3f4f6;
            color: #4b5563;
            font-style: italic;
            text-align: center;
            border-radius: 15px;
            max-width: 60%;
        }

        .message.system.error {
            background: #fef2f2;
            color: #dc2626;
        }

        .message.system.success {
            background: #f0fdf4;
            color: #16a34a;
        }

        .message-header {
            font-size: 0.8rem;
            opacity: 0.7;
            margin-bottom: 5px;
        }

        .chat-input-area {
            padding: 20px 30px;
            background: #f9fafb;
            border-top: 1px solid #e5e7eb;
        }

        .input-container {
            display: flex;
            gap: 10px;
            align-items: flex-end;
        }

        .text-input-area {
            flex: 1;
            position: relative;
        }

        .text-input {
            width: 100%;
            min-height: 50px;
            max-height: 150px;
            padding: 15px 50px 15px 15px;
            border: 1px solid #d1d5db;
            border-radius: 24px;
            resize: vertical;
            font-family: inherit;
            font-size: 16px;
            outline: none;
            transition: border-color 0.3s ease;
        }

        .text-input:focus {
            border-color: #374151;
        }

        .voice-toggle {
            position: absolute;
            right: 10px;
            top: 50%;
            transform: translateY(-50%);
            background: none;
            border: none;
            cursor: pointer;
            padding: 8px;
            border-radius: 50%;
            transition: background-color 0.3s ease;
        }

        .voice-toggle:hover {
            background: #f3f4f6;
        }

        .voice-toggle.active {
            background: #ef4444;
            color: white;
        }

        .send-button {
            background: #374151;
            color: white;
            border: none;
            padding: 15px 25px;
            border-radius: 24px;
            cursor: pointer;
            font-size: 16px;
            transition: all 0.2s ease;
        }

        .send-button:hover {
            background: #1f2937;
            transform: translateY(-1px);
        }

        .send-button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }

        /* Audio Visualizer */
        .audio-visualizer {
            display: none;
            background: #1f2937;
            border-radius: 8px;
            height: 60px;
            margin: 10px 0;
            position: relative;
            overflow: hidden;
        }

        .audio-visualizer.active {
            display: block;
        }

        .audio-bars {
            display: flex;
            align-items: flex-end;
            height: 100%;
            padding: 10px;
            gap: 2px;
        }

        .bar {
            background: linear-gradient(to top, #6b7280, #9ca3af);
            width: 4px;
            border-radius: 2px 2px 0 0;
            transition: height 0.1s ease;
            min-height: 2px;
        }

        /* Status indicators */
        .status-indicator {
            padding: 10px 15px;
            border-radius: 20px;
            font-size: 0.9rem;
            margin: 10px 0;
            text-align: center;
        }

        .status-indicator.connected {
            background: #f0fdf4;
            color: #15803d;
            border: 1px solid #bbf7d0;
        }

        .status-indicator.connecting {
            background: #fffbeb;
            color: #d97706;
            border: 1px solid #fed7aa;
        }

        .status-indicator.error {
            background: #fef2f2;
            color: #dc2626;
            border: 1px solid #fecaca;
        }

        /* Loading animation */
        .typing-indicator {
            display: none;
            align-items: center;
            padding: 15px 20px;
            background: #f9fafb;
            border-radius: 20px;
            max-width: 80px;
        }

        .typing-indicator.show {
            display: flex;
            margin: 20px 30px
        }

        .typing-dot {
            width: 8px;
            height: 8px;
            border-radius: 50%;
            background: #9ca3af;
            margin: 0 2px;
            animation: typing 1.4s infinite;
        }

        .typing-dot:nth-child(1) { animation-delay: 0s; }
        .typing-dot:nth-child(2) { animation-delay: 0.2s; }
        .typing-dot:nth-child(3) { animation-delay: 0.4s; }

        @keyframes typing {
            0%, 60%, 100% {
                transform: translateY(0);
            }
            30% {
                transform: translateY(-10px);
            }
        }

        /* Responsive Design */
        @media (max-width: 768px) {
            .main-content {
                flex-direction: column;
                height: auto;
            }
            
            .sidebar {
                width: 100%;
                order: 2;
            }
            
            .chat-area {
                order: 1;
                min-height: 60vh;
            }
        }

        /* Footer Styles */
        .app-footer {
            background: #1f2937;
            color: #e5e7eb;
            padding: 20px 30px;
            text-align: center;
            font-size: 0.9rem;
            border-top: 1px solid #374151;
        }

        .app-footer .company-info {
            margin-bottom: 5px;
        }

        .app-footer .tech-info {
            font-size: 0.8rem;
            opacity: 0.8;
        }

        /* Utility classes */
        .hidden {
            display: none !important;
        }

        .error {
            color: #dc2626;
        }

        .success {
            color: #16a34a;
        }
    </style>
</head>
<body>
    <div class="app-container">
        <div class="header">
            <h1>ü§ñ AI Assistant</h1>
            <p>Multi-Agent Chatbot with Document Upload & Voice Input</p>
        </div>

        <div class="main-content">
            <!-- Sidebar -->
            <div class="sidebar">
                <!-- Agent Selection -->
                <div class="agent-selector">
                    <h3>üé≠ Select Agent</h3>
                    <button class="agent-option active" data-agent="single">
                        <span class="agent-name">üìö Single Agent <span class="message-count" id="count-single">0</span></span>
                        <span class="agent-desc">General purpose assistant</span>
                    </button>
                    <button class="agent-option" data-agent="multi">
                        <span class="agent-name">üéØ Multi Agent (Triage) <span class="message-count" id="count-multi">0</span></span>
                        <span class="agent-desc">Smart task routing</span>
                    </button>
                    <button class="agent-option" data-agent="handsoff">
                        <span class="agent-name">üöÄ Hands-Off Agent <span class="message-count" id="count-handsoff">0</span></span>
                        <span class="agent-desc">Autonomous workflow w/ Document Search Agent</span>
                    </button>
                </div>

                <!-- Document Upload -->
                <div class="document-upload">
                    <h3>üìé Upload Documents</h3>
                    <div class="upload-area" id="uploadArea">
                        <div>
                            <strong>üìÅ Drop files here</strong><br>
                            <small>or click to browse</small><br>
                            <small>Supported: PDF, DOCX, TXT</small>
                        </div>
                        <input type="file" id="fileInput" multiple accept=".pdf,.docx,.txt" style="display: none;">
                    </div>
                    <div id="uploadStatus" class="status-indicator hidden"></div>
                </div>

                <!-- Speech Status -->
                <div class="speech-status">
                    <h3>üé§ Speech Recognition</h3>
                    <div id="speechStatus" class="status-indicator">Not connected</div>
                    <select id="languageSelect">
                        <option value="en-US">English (US)</option>
                        <option value="id-ID">Indonesia</option>
                        <option value="en-GB">English (UK)</option>
                        <option value="fr-FR">French</option>
                        <option value="de-DE">German</option>
                        <option value="es-ES">Spanish</option>
                    </select>
                </div>
            </div>

            <!-- Chat Area -->
            <div class="chat-area">
                <div class="chat-header">
                    <h3 id="currentAgentTitle">üìö Single Agent</h3>
                    <button id="clearChatButton" class="agent-option" style="padding: 8px 15px; margin: 0;">
                        üóëÔ∏è Clear Chat
                    </button>
                </div>

                <div class="chat-messages" id="chatMessages">
                    <div class="message system">
                        <div class="message-header">System</div>
                        Welcome! Select an agent and start chatting. You can type or use voice input.
                    </div>
                </div>

                <div class="typing-indicator" id="typingIndicator">
                    <div class="typing-dot"></div>
                    <div class="typing-dot"></div>
                    <div class="typing-dot"></div>
                </div>

                <div class="chat-input-area">
                    <div class="audio-visualizer" id="audioVisualizer">
                        <div class="audio-bars" id="audioBars"></div>
                    </div>
                    
                    <div class="input-container">
                        <div class="text-input-area">
                            <textarea 
                                id="messageInput" 
                                class="text-input" 
                                placeholder="Type your message here... (or click the mic to speak)"
                                rows="2"
                            ></textarea>
                            <button id="voiceToggle" class="voice-toggle" title="Voice Input">
                                üé§
                            </button>
                        </div>
                        <button id="sendButton" class="send-button">
                            Send
                        </button>
                    </div>
                </div>
            </div>
        </div>

        <!-- Footer -->
        <div class="app-footer">
            <div class="company-info" id="companyInfo">
                Created by Mitra Integrasi Informatika - Microsoft Azure Team
            </div>
            <div class="tech-info">
                Using Azure AI Foundry and Azure OpenAI Technology
            </div>
        </div>
    </div>

    <script>
        /* 
         * Audio Streaming Configuration Guide:
         * 
         * To configure audio streaming at code level, use:
         * 
         * 1. Direct configuration:
         *    configureAudio({
         *        bufferSizeMs: 300,        // Buffer duration (125-500ms)
         *        silenceThreshold: 0.015,  // Silence detection (0.001-0.1)
         *        maxSilenceMs: 400,        // Max silence before flush (250-1000ms)
         *        adaptiveBuffering: true,  // Enable adaptive buffering
         *        compressionEnabled: true, // Enable zlib compression
         *        logPerformance: true      // Log performance stats
         *    });
         * 
         * 2. Use presets:
         *    useAudioPreset('high_quality');    // 500ms buffers, best quality
         *    useAudioPreset('balanced');        // 250ms buffers, good balance
         *    useAudioPreset('low_latency');     // 125ms buffers, fastest response
         *    useAudioPreset('noisy_environment'); // 350ms buffers, noise resilient
         * 
         * 3. Current benefits:
         *    - Reduces WebSocket messages from ~125/sec to ~4-10/sec
         *    - Improves compression ratio from ~35% to ~70%
         *    - Maintains low latency (250-500ms vs original 8ms)
         *    - Adaptive buffering adjusts to speech patterns
         * 
         * Call these functions in browser console or after page load.
         */
         
        // Global variables for the application
        let currentAgent = 'single';
        let isVoiceMode = false;
        let websocket = null;
        let pingInterval = null;
        let audioContext = null;
        let audioWorkletNode = null;
        let audioStream = null;
        let audioAnalyzer = null;
        let visualizerInterval = null;
        
        // Audio streaming configuration
        let audioConfig = {
            bufferSizeMs: 250,          // Buffer duration (125-500ms recommended)
            silenceThreshold: 0.01,     // Silence detection threshold (0.001-0.1)
            maxSilenceMs: 500,          // Max silence before flushing buffer (250-1000ms)
            adaptiveBuffering: true,    // Adapt buffer size based on speech patterns
            logPerformance: true,       // Log compression and timing stats
            compressionEnabled: true,   // Enable/disable audio compression
            
            // Advanced settings
            minBufferSizeMs: 125,       // Minimum buffer size for adaptive mode
            maxBufferSizeMs: 500,       // Maximum buffer size for adaptive mode
            speechDetectionWindow: 100, // Window for speech detection (ms)
            compressionLevel: 6,        // Compression level (1-9, higher = better compression)
            
            // Performance monitoring
            messagesPerSecond: 0,       // Current message rate
            avgCompressionRatio: 0,     // Average compression ratio
            lastPerformanceLog: 0       // Last performance log timestamp
        };

        // Separate chat histories for each agent
        let chatHistories = {
            'single': [],
            'multi': [],
            'handsoff': []
        };

        // Compression utilities using pako
        function compressBase64(base64Data) {
            try {
                // Convert base64 to Uint8Array
                const binaryString = atob(base64Data);
                const bytes = new Uint8Array(binaryString.length);
                for (let i = 0; i < binaryString.length; i++) {
                    bytes[i] = binaryString.charCodeAt(i);
                }
                
                // Compress using pako
                const compressed = pako.deflate(bytes);
                
                // Convert back to base64
                const compressedBase64 = btoa(String.fromCharCode(...compressed));
                
                console.log(`Compression ratio: ${((1 - compressed.length / bytes.length) * 100).toFixed(1)}% (${bytes.length} -> ${compressed.length} bytes)`);
                
                return compressedBase64;
            } catch (error) {
                console.error('Error compressing data:', error);
                return base64Data; // Return original data if compression fails
            }
        }

        function decompressBase64(compressedBase64) {
            try {
                // Convert base64 to Uint8Array
                const binaryString = atob(compressedBase64);
                const bytes = new Uint8Array(binaryString.length);
                for (let i = 0; i < binaryString.length; i++) {
                    bytes[i] = binaryString.charCodeAt(i);
                }
                
                // Decompress using pako
                const decompressed = pako.inflate(bytes);
                
                // Convert back to base64
                const decompressedBase64 = btoa(String.fromCharCode(...decompressed));
                
                return decompressedBase64;
            } catch (error) {
                console.error('Error decompressing data:', error);
                return compressedBase64; // Return original data if decompression fails
            }
        }

        // DOM elements
        const elements = {
            agentOptions: document.querySelectorAll('.agent-option'),
            currentAgentTitle: document.getElementById('currentAgentTitle'),
            messageInput: document.getElementById('messageInput'),
            sendButton: document.getElementById('sendButton'),
            chatMessages: document.getElementById('chatMessages'),
            voiceToggle: document.getElementById('voiceToggle'),
            audioVisualizer: document.getElementById('audioVisualizer'),
            audioBars: document.getElementById('audioBars'),
            speechStatus: document.getElementById('speechStatus'),
            languageSelect: document.getElementById('languageSelect'),
            uploadArea: document.getElementById('uploadArea'),
            fileInput: document.getElementById('fileInput'),
            uploadStatus: document.getElementById('uploadStatus'),
            clearChatButton: document.getElementById('clearChatButton'),
            typingIndicator: document.getElementById('typingIndicator')
        };

        // Initialize the application
        document.addEventListener('DOMContentLoaded', function() {
            console.log('ü§ñ AI Assistant initialized');
            
            // Initialize optimized audio configuration
            useAudioPreset('balanced'); // Default to balanced preset
            
            // Initialize event listeners
            initializeEventListeners();
            
            // Initialize speech recognition
            initializeSpeechRecognition();
            
            // Load initial chat room (single agent)
            loadChatHistory(currentAgent);
            
            // Initialize message count indicators
            updateMessageCount();
            
            // Initialize footer with partner name
            initializeFooter();
            
            // Add initial welcome message if no history exists
            if (chatHistories[currentAgent].length === 0) {
                addSystemMessage('Welcome to Single Agent! I\'m a general-purpose assistant ready to help.', 'success');
            }
            
            // Add application ready message
            addSystemMessage('Application initialized. Ready to chat!', 'temp');
        });

        function initializeEventListeners() {
            // Agent selection
            elements.agentOptions.forEach(option => {
                option.addEventListener('click', () => selectAgent(option.dataset.agent));
            });

            // Send message
            elements.sendButton.addEventListener('click', sendMessage);
            elements.messageInput.addEventListener('keypress', (e) => {
                if (e.key === 'Enter' && !e.shiftKey) {
                    e.preventDefault();
                    sendMessage();
                }
            });

            // Voice toggle
            elements.voiceToggle.addEventListener('click', toggleVoiceMode);

            // File upload
            elements.uploadArea.addEventListener('click', () => elements.fileInput.click());
            elements.uploadArea.addEventListener('dragover', handleDragOver);
            elements.uploadArea.addEventListener('dragleave', (e) => {
                if (!elements.uploadArea.contains(e.relatedTarget)) {
                    elements.uploadArea.classList.remove('dragover');
                }
            });
            elements.uploadArea.addEventListener('drop', handleFileDrop);
            elements.fileInput.addEventListener('change', handleFileSelect);

            // Clear chat
            elements.clearChatButton.addEventListener('click', clearChat);

            // Language selection
            elements.languageSelect.addEventListener('change', updateSpeechLanguage);
        }

        async function initializeFooter() {
            try {
                // Fetch partner name from backend
                const response = await fetch('/config/partner-name');
                
                if (response.ok) {
                    const data = await response.json();
                    const companyInfoElement = document.getElementById('companyInfo');
                    
                    if (data.partnerName) {
                        companyInfoElement.textContent = `Created by Mitra Integrasi Informatika - Microsoft Azure Team for ${data.partnerName}`;
                    } else {
                        companyInfoElement.textContent = 'Created by Mitra Integrasi Informatika - Microsoft Azure Team';
                    }
                } else {
                    console.log('Partner name endpoint not available, using default footer text');
                }
            } catch (error) {
                console.log('Could not fetch partner name:', error.message);
                // Footer will keep default text if fetch fails
            }
        }

        // Placeholder functions - will be implemented in next steps
        function selectAgent(agent) {
            // Save current chat history before switching
            if (currentAgent !== agent) {
                saveChatHistory(currentAgent);
            }
            
            // Update current agent
            currentAgent = agent;
            
            // Update UI
            elements.agentOptions.forEach(option => {
                option.classList.remove('active');
                if (option.dataset.agent === agent) {
                    option.classList.add('active');
                }
            });
            
            // Update title
            const agentTitles = {
                'single': 'üìö Single Agent',
                'multi': 'üéØ Multi Agent (Triage)',
                'handsoff': 'üöÄ Hands-Off Agent'
            };
            elements.currentAgentTitle.textContent = agentTitles[agent];
            
            // Load chat history for the selected agent
            loadChatHistory(agent);
            
            // Add system message about the switch
            const welcomeMessages = {
                'single': 'Welcome to Single Agent! I\'m a general-purpose assistant ready to help.',
                'multi': 'Welcome to Multi Agent! I\'ll intelligently route your requests to specialized agents.',
                'handsoff': 'Welcome to Hands-Off Agent! I can work autonomously on complex tasks.'
            };
            
            // // Only add welcome message if this is a new chat room (empty history)
            // if (chatHistories[agent].length === 0) {
            //     addSystemMessage(welcomeMessages[agent], 'success');
            // } else {
            //     addSystemMessage(`Switched to ${agentTitles[agent]} chat room`);
            // }
            
            console.log(`Agent selected: ${agent}`);
        }

        async function sendMessage() {
            const message = elements.messageInput.value.trim();
            if (!message) return;
            
            // Clear input and disable send button
            elements.messageInput.value = '';
            elements.sendButton.disabled = true;
            
            // Add user message to chat
            addUserMessage(message);
            
            // Show typing indicator
            elements.typingIndicator.classList.add('show');
            
            scrollToBottom()

            try {
                // Send message to appropriate agent endpoint
                const response = await sendToAgent(currentAgent, message);
                
                // Add assistant response
                addAssistantMessage(response.response || response.message || 'No response received');
                
            } catch (error) {
                console.error('Error sending message:', error);
                addSystemMessage(`Error: ${error.message}`, 'error');
            } finally {
                // Hide typing indicator and re-enable send button
                elements.typingIndicator.classList.remove('show');
                elements.sendButton.disabled = false;
                elements.messageInput.focus();
            }
        }

        async function sendToAgent(agent, message) {
            const endpoints = {
                'single': '/single/chat',
                'multi': '/multi/chat', 
                'handsoff': '/handsoff/chat'
            };
            
            const endpoint = endpoints[agent];
            if (!endpoint) {
                throw new Error(`Unknown agent: ${agent}`);
            }
            
            // Different agents use different request methods
            if (agent === 'single') {
                // Single agent uses GET with query parameter
                const response = await fetch(`${endpoint}?chat=${encodeURIComponent(message)}`);
                if (!response.ok) {
                    throw new Error(`HTTP error! status: ${response.status}`);
                }
                return await response.json();
            } else {
                // Multi and handsoff agents use POST with JSON body
                const response = await fetch(endpoint, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({ chat: message })
                });
                
                if (!response.ok) {
                    throw new Error(`HTTP error! status: ${response.status}`);
                }
                return await response.json();
            }
        }

        function addUserMessage(message) {
            const messageElement = document.createElement('div');
            messageElement.className = 'message user';
            messageElement.innerHTML = `
                <div class="message-header">You</div>
                ${escapeHtml(message)}
            `;
            elements.chatMessages.appendChild(messageElement);
            scrollToBottom();
            
            // Add to current agent's chat history
            chatHistories[currentAgent].push({
                type: 'user',
                message: message,
                timestamp: new Date().toISOString()
            });
            
            // Update message count
            updateMessageCount();
        }

        function addAssistantMessage(message) {
            const messageElement = document.createElement('div');
            messageElement.className = 'message assistant';
            messageElement.innerHTML = `
                <div class="message-header">${getAgentName(currentAgent)}</div>
                ${escapeHtml(message)}
            `;
            elements.chatMessages.appendChild(messageElement);
            scrollToBottom();
            
            // Add to current agent's chat history
            chatHistories[currentAgent].push({
                type: 'assistant',
                message: message,
                agent: currentAgent,
                timestamp: new Date().toISOString()
            });
            
            // Update message count
            updateMessageCount();
        }

        function addSystemMessage(message, type = 'info') {
            const messageElement = document.createElement('div');
            messageElement.className = `message system ${type}`;
            messageElement.innerHTML = `
                <div class="message-header">System</div>
                ${escapeHtml(message)}
            `;
            elements.chatMessages.appendChild(messageElement);
            scrollToBottom();
            
            // Add to current agent's chat history (only non-temporary system messages)
            if (type !== 'temp') {
                chatHistories[currentAgent].push({
                    type: 'system',
                    message: message,
                    messageType: type,
                    timestamp: new Date().toISOString()
                });
                
                // Update message count
                updateMessageCount();
            }
        }

        function saveChatHistory(agent) {
            // Chat history is already saved in real-time to chatHistories object
            // This function can be extended for localStorage persistence if needed
            console.log(`Saving chat history for ${agent}: ${chatHistories[agent].length} messages`);
        }

        function updateMessageCount() {
            // Update message count indicators for all agents
            Object.keys(chatHistories).forEach(agent => {
                const agentButton = document.querySelector(`[data-agent="${agent}"]`);
                if (agentButton) {
                    const count = chatHistories[agent].length;
                    let countBadge = agentButton.querySelector('.message-count');
                    
                    if (count > 0) {
                        if (!countBadge) {
                            countBadge = document.createElement('span');
                            countBadge.className = 'message-count';
                            agentButton.appendChild(countBadge);
                        }
                        countBadge.textContent = count;
                        countBadge.style.display = 'inline-block';
                    } else if (countBadge) {
                        countBadge.style.display = 'none';
                    }
                }
            });
        }

        function loadChatHistory(agent) {
            // Clear current chat display
            elements.chatMessages.innerHTML = '';
            
            // Load messages from history
            const history = chatHistories[agent];
            
            history.forEach(item => {
                let messageElement = document.createElement('div');
                
                switch(item.type) {
                    case 'user':
                        messageElement.className = 'message user';
                        messageElement.innerHTML = `
                            <div class="message-header">You</div>
                            ${escapeHtml(item.message)}
                        `;
                        break;
                        
                    case 'assistant':
                        messageElement.className = 'message assistant';
                        messageElement.innerHTML = `
                            <div class="message-header">${getAgentName(item.agent || agent)}</div>
                            ${escapeHtml(item.message)}
                        `;
                        break;
                        
                    case 'system':
                        messageElement.className = `message system ${item.messageType || 'info'}`;
                        messageElement.innerHTML = `
                            <div class="message-header">System</div>
                            ${escapeHtml(item.message)}
                        `;
                        break;
                }
                
                elements.chatMessages.appendChild(messageElement);
            });
            
            scrollToBottom();
        }

        function getAgentName(agent) {
            const names = {
                'single': 'Single Agent',
                'multi': 'Multi Agent',
                'handsoff': 'Hands-Off Agent'
            };
            return names[agent] || 'Assistant';
        }

        function escapeHtml(text) {
            const div = document.createElement('div');
            div.textContent = text;
            return div.innerHTML;
        }

        function scrollToBottom() {
            elements.chatMessages.scrollTop = elements.chatMessages.scrollHeight;
        }

        function toggleVoiceMode() {
            if (!isVoiceMode) {
                startVoiceRecording();
            } else {
                stopVoiceRecording();
            }
        }

        function initializeSpeechRecognition() {
            console.log('Initializing speech recognition...');
            
            // Initialize audio visualizer
            initAudioVisualizer();
            
            // Connect to WebSocket for speech recognition
            connectSpeechWebSocket();
        }

        function handleDragOver(e) {
            e.preventDefault();
            elements.uploadArea.classList.add('dragover');
        }

        function handleFileDrop(e) {
            e.preventDefault();
            elements.uploadArea.classList.remove('dragover');
            
            const files = Array.from(e.dataTransfer.files);
            uploadFiles(files);
        }

        function handleFileSelect(e) {
            const files = Array.from(e.target.files);
            uploadFiles(files);
            // Reset the input so the same file can be selected again
            e.target.value = '';
        }

        async function uploadFiles(files) {
            if (files.length === 0) return;
            
            // Show upload status
            elements.uploadStatus.className = 'status-indicator connecting';
            elements.uploadStatus.textContent = 'Preparing to upload...';
            elements.uploadStatus.classList.remove('hidden');
            
            for (let i = 0; i < files.length; i++) {
                const file = files[i];
                
                // Check file type
                const allowedTypes = ['.pdf', '.docx', '.txt'];
                const fileExtension = '.' + file.name.split('.').pop().toLowerCase();
                
                if (!allowedTypes.includes(fileExtension)) {
                    showUploadError(`File "${file.name}" is not supported. Only PDF, DOCX, and TXT files are allowed.`);
                    continue;
                }
                
                // Check file size (limit to 10MB)
                if (file.size > 10 * 1024 * 1024) {
                    showUploadError(`File "${file.name}" is too large. Maximum size is 10MB.`);
                    continue;
                }
                
                try {
                    elements.uploadStatus.textContent = `Uploading ${file.name}... (${i + 1}/${files.length})`;
                    
                    const formData = new FormData();
                    formData.append('file', file);
                    
                    const response = await fetch('/documents/upload', {
                        method: 'POST',
                        body: formData
                    });
                    
                    if (!response.ok) {
                        throw new Error(`Upload failed: ${response.status} ${response.statusText}`);
                    }
                    
                    const result = await response.json();
                    
                    // Show success message
                    addSystemMessage(`‚úÖ Successfully uploaded "${file.name}" - ${result.chunks_processed} chunks processed`, 'success');
                    
                } catch (error) {
                    console.error('Upload error:', error);
                    showUploadError(`Failed to upload "${file.name}": ${error.message}`);
                }
            }
            
            // Hide upload status after a delay
            setTimeout(() => {
                elements.uploadStatus.classList.add('hidden');
            }, 3000);
        }

        function showUploadError(message) {
            elements.uploadStatus.className = 'status-indicator error';
            elements.uploadStatus.textContent = message;
            addSystemMessage(message, 'error');
            
            setTimeout(() => {
                elements.uploadStatus.classList.add('hidden');
            }, 5000);
        }

        function initAudioVisualizer() {
            const barsContainer = elements.audioBars;
            barsContainer.innerHTML = '';
            
            // Create 40 bars for visualization
            for (let i = 0; i < 40; i++) {
                const bar = document.createElement('div');
                bar.className = 'bar';
                bar.style.height = '2px';
                barsContainer.appendChild(bar);
            }
        }

        function connectSpeechWebSocket() {
            const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsUrl = `${protocol}//${window.location.host}/speech/stream`;
            
            websocket = new WebSocket(wsUrl);
            
            websocket.onopen = function(event) {
                console.log('Speech WebSocket connected');
                updateSpeechStatus('Connected', 'connected');
                
                // Send initial configuration
                const language = elements.languageSelect.value;
                websocket.send(JSON.stringify({
                    type: 'config',
                    language: language,
                    source: 'webrtc'
                }));
                
                // Start ping interval to keep connection alive
                startPingInterval();
            };
            
            websocket.onmessage = function(event) {
                const data = JSON.parse(event.data);
                handleSpeechMessage(data);
            };
            
            websocket.onclose = function(event) {
                console.log('Speech WebSocket disconnected');
                updateSpeechStatus('Disconnected', 'error');
                
                // Stop ping interval
                stopPingInterval();
                
                if (isVoiceMode) {
                    stopVoiceRecording();
                }
                
                // Try to reconnect after a delay
                setTimeout(connectSpeechWebSocket, 3000);
            };
            
            websocket.onerror = function(error) {
                console.error('Speech WebSocket error:', error);
                updateSpeechStatus('Connection Error', 'error');
                stopPingInterval();
            };
        }

        function updateSpeechStatus(message, type) {
            elements.speechStatus.textContent = message;
            elements.speechStatus.className = `status-indicator ${type}`;
        }

        function handleSpeechMessage(data) {
            console.log('Speech message received:', data);
            
            switch(data.type) {
                case 'config_success':
                    updateSpeechStatus('Ready', 'connected');
                    break;
                    
                case 'start_success':
                    updateSpeechStatus('Listening...', 'connecting');
                    break;
                    
                case 'stop_success':
                    updateSpeechStatus('Ready', 'connected');
                    break;
                    
                case 'error':
                    console.error('Speech error:', data.message);
                    updateSpeechStatus(`Error: ${data.message}`, 'error');
                    addSystemMessage(`Speech Error: ${data.message}`, 'error');
                    if (isVoiceMode) {
                        stopVoiceRecording();
                    }
                    break;
                    
                case 'pong':
                    // Handle pong response from server (keep-alive confirmation)
                    console.log('Received pong from server');
                    break;
                    
                default:
                    // Handle recognition results
                    if (data.finish !== undefined) {
                        if (data.finish) {
                            // Final result - add to text input and stop recording
                            if (data.text && data.text.trim()) {
                                elements.messageInput.value = data.text.trim();
                                stopVoiceRecording();
                                
                                // Auto-send if enabled
                                // sendMessage(); // Uncomment for auto-send
                            }
                        } else {
                            // Intermediate result - show in text input
                            if (data.text) {
                                elements.messageInput.value = data.text;
                            }
                        }
                    }
                    break;
            }
        }

        function startPingInterval() {
            // Send ping every 2 seconds to keep WebSocket connection alive
            if (pingInterval) {
                clearInterval(pingInterval);
            }
            
            pingInterval = setInterval(() => {
                if (websocket && websocket.readyState === WebSocket.OPEN) {
                    websocket.send(JSON.stringify({
                        type: 'ping',
                        timestamp: new Date().toISOString()
                    }));
                    console.log('Sent ping to server');
                } else {
                    // Stop ping if WebSocket is not connected
                    stopPingInterval();
                }
            }, 2000); // Send ping every 2 seconds
        }

        function stopPingInterval() {
            if (pingInterval) {
                clearInterval(pingInterval);
                pingInterval = null;
                console.log('Stopped ping interval');
            }
        }

        async function startVoiceRecording() {
            if (!websocket || websocket.readyState !== WebSocket.OPEN) {
                addSystemMessage('Speech recognition not connected. Please wait...', 'error');
                return;
            }
            
            try {
                // Get user media with optimal settings for speech recognition
                audioStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        sampleRate: 16000,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true,
                        sampleSize: 16
                    }
                });

                // Setup audio context and processing
                audioContext = new AudioContext({ sampleRate: 16000 });
                
                // Create audio worklet for processing
                const audioWorkletProcessor = `
                    class AudioProcessor extends AudioWorkletProcessor {
                        constructor() {
                            super();
                            this.isRecording = false;
                            this.audioBuffer = [];
                            this.bufferSizeMs = 250; // Buffer 250ms of audio (configurable)
                            this.sampleRate = 16000;
                            this.samplesPerBuffer = Math.floor((this.bufferSizeMs / 1000) * this.sampleRate);
                            this.silenceThreshold = 0.01; // Configurable silence detection
                            this.silenceCounter = 0;
                            this.maxSilenceMs = 500; // Max silence before flushing buffer
                            this.maxSilenceSamples = Math.floor((this.maxSilenceMs / 1000) * this.sampleRate);
                            
                            // Performance tracking
                            this.messageCount = 0;
                            this.startTime = currentTime;
                            this.lastLogTime = currentTime;
                            this.compressionStats = [];
                            
                            // Adaptive buffering
                            this.speechDetectionBuffer = [];
                            this.speechDetectionWindowSamples = Math.floor((100 / 1000) * this.sampleRate); // 100ms window
                            this.adaptiveEnabled = false;
                            this.currentBufferOptimal = this.bufferSizeMs;
                            
                            this.port.onmessage = (event) => {
                                if (event.data.command === 'start') {
                                    this.isRecording = true;
                                    this.audioBuffer = [];
                                    this.silenceCounter = 0;
                                    this.messageCount = 0;
                                    this.startTime = currentTime;
                                } else if (event.data.command === 'stop') {
                                    this.isRecording = false;
                                    // Flush any remaining buffer
                                    if (this.audioBuffer.length > 0) {
                                        this.flushBuffer();
                                    }
                                    // Log final performance stats
                                    this.logPerformanceStats(true);
                                } else if (event.data.command === 'configure') {
                                    // Allow runtime configuration
                                    if (event.data.bufferSizeMs) {
                                        this.bufferSizeMs = event.data.bufferSizeMs;
                                        this.samplesPerBuffer = Math.floor((this.bufferSizeMs / 1000) * this.sampleRate);
                                        this.currentBufferOptimal = this.bufferSizeMs;
                                    }
                                    if (event.data.silenceThreshold !== undefined) {
                                        this.silenceThreshold = event.data.silenceThreshold;
                                    }
                                    if (event.data.maxSilenceMs) {
                                        this.maxSilenceMs = event.data.maxSilenceMs;
                                        this.maxSilenceSamples = Math.floor((this.maxSilenceMs / 1000) * this.sampleRate);
                                    }
                                    if (event.data.adaptiveBuffering !== undefined) {
                                        this.adaptiveEnabled = event.data.adaptiveBuffering;
                                    }
                                    if (event.data.speechDetectionWindow) {
                                        this.speechDetectionWindowSamples = Math.floor((event.data.speechDetectionWindow / 1000) * this.sampleRate);
                                    }
                                }
                            };
                        }
                        
                        process(inputs, outputs, parameters) {
                            if (!this.isRecording) return true;
                            
                            const input = inputs[0];
                            if (input && input[0]) {
                                const samples = input[0];
                                const pcmSamples = new Int16Array(samples.length);
                                
                                // Convert float32 to PCM16 and detect silence
                                let hasSignificantAudio = false;
                                for (let i = 0; i < samples.length; i++) {
                                    const sample = Math.max(-1, Math.min(1, samples[i]));
                                    pcmSamples[i] = sample * 0x7FFF;
                                    
                                    // Check for significant audio (above silence threshold)
                                    if (Math.abs(sample) > this.silenceThreshold) {
                                        hasSignificantAudio = true;
                                    }
                                }
                                
                                // Add samples to buffer
                                this.audioBuffer.push(...pcmSamples);
                                
                                // Update silence counter
                                if (hasSignificantAudio) {
                                    this.silenceCounter = 0;
                                } else {
                                    this.silenceCounter += samples.length;
                                }
                                
                                // Check if we should flush the buffer
                                const shouldFlush = 
                                    this.audioBuffer.length >= this.samplesPerBuffer || // Buffer is full
                                    this.silenceCounter >= this.maxSilenceSamples;     // Too much silence
                                
                                if (shouldFlush && this.audioBuffer.length > 0) {
                                    this.flushBuffer();
                                }
                            }
                            
                            return true;
                        }
                        
                        flushBuffer() {
                            if (this.audioBuffer.length === 0) return;
                            
                            // Create final buffer from accumulated samples
                            const finalBuffer = new Int16Array(this.audioBuffer);
                            
                            this.port.postMessage({
                                type: 'audioData',
                                data: finalBuffer.buffer,
                                sampleCount: finalBuffer.length,
                                durationMs: (finalBuffer.length / this.sampleRate) * 1000
                            });
                            
                            // Performance tracking
                            this.messageCount++;
                            
                            // Reset buffer and silence counter
                            this.audioBuffer = [];
                            this.silenceCounter = 0;
                        }
                        
                        logPerformanceStats(final = false) {
                            const now = currentTime;
                            if (final || (now - this.lastLogTime) > 10) { // Log every 10 seconds or on final
                                const duration = now - this.startTime;
                                const messagesPerSecond = duration > 0 ? this.messageCount / duration : 0;
                                
                                console.log('Audio Performance - Messages: ' + this.messageCount + 
                                           ', Rate: ' + messagesPerSecond.toFixed(1) + '/sec' +
                                           ', Duration: ' + duration.toFixed(1) + 's');
                                
                                this.lastLogTime = now;
                            }
                        }
                    }
                    
                    registerProcessor('audio-processor', AudioProcessor);
                `;
                
                const blob = new Blob([audioWorkletProcessor], { type: 'application/javascript' });
                const workletUrl = URL.createObjectURL(blob);
                await audioContext.audioWorklet.addModule(workletUrl);
                URL.revokeObjectURL(workletUrl);
                
                // Create worklet node
                audioWorkletNode = new AudioWorkletNode(audioContext, 'audio-processor');
                audioWorkletNode.port.onmessage = (event) => {
                    if (event.data.type === 'audioData' && isVoiceMode && websocket && websocket.readyState === WebSocket.OPEN) {
                        // Send buffered audio data to WebSocket with compression
                        const base64Data = btoa(String.fromCharCode(...new Uint8Array(event.data.data)));
                        const compressedData = compressBase64(base64Data);
                        
                        console.log('Sending audio buffer: ' + event.data.sampleCount + ' samples (' + 
                                   event.data.durationMs.toFixed(1) + 'ms), compression: ' + 
                                   ((1 - compressedData.length / base64Data.length) * 100).toFixed(1) + '%');
                        
                        websocket.send(JSON.stringify({
                            type: 'audio',
                            data: compressedData,
                            format: 'pcm16',
                            sampleRate: 16000,
                            sampleCount: event.data.sampleCount,
                            durationMs: event.data.durationMs,
                            compressed: true // Indicate that data is compressed
                        }));
                    }
                };

                // Configure audio worklet with optimized settings from config
                audioWorkletNode.port.postMessage({
                    command: 'configure',
                    bufferSizeMs: audioConfig.bufferSizeMs,
                    silenceThreshold: audioConfig.silenceThreshold,
                    maxSilenceMs: audioConfig.maxSilenceMs,
                    adaptiveBuffering: audioConfig.adaptiveBuffering,
                    speechDetectionWindow: audioConfig.speechDetectionWindow
                });

                // Setup audio analyzer for visualization
                audioAnalyzer = audioContext.createAnalyser();
                audioAnalyzer.fftSize = 256;
                
                // Connect audio nodes
                const source = audioContext.createMediaStreamSource(audioStream);
                source.connect(audioWorkletNode);
                source.connect(audioAnalyzer);
                
                // Send start message to WebSocket
                websocket.send(JSON.stringify({type: 'start'}));
                
                // Start audio processing
                audioWorkletNode.port.postMessage({command: 'start'});
                
                // Update UI
                isVoiceMode = true;
                elements.voiceToggle.classList.add('active');
                elements.voiceToggle.textContent = '‚èπÔ∏è';
                elements.voiceToggle.title = 'Stop Voice Input';
                elements.audioVisualizer.classList.add('active');
                elements.messageInput.placeholder = 'Listening... speak now or click stop to finish';
                
                // Start audio visualization
                startAudioVisualization();
                
            } catch (error) {
                console.error('Error starting voice recording:', error);
                addSystemMessage(`Failed to start voice recording: ${error.message}`, 'error');
                updateSpeechStatus('Error', 'error');
            }
        }

        function stopVoiceRecording() {
            if (!isVoiceMode) return;
            
            // Send stop message to WebSocket
            if (websocket && websocket.readyState === WebSocket.OPEN) {
                websocket.send(JSON.stringify({type: 'stop'}));
            }
            
            // Stop audio processing
            if (audioWorkletNode) {
                audioWorkletNode.port.postMessage({command: 'stop'});
                audioWorkletNode.disconnect();
                audioWorkletNode = null;
            }
            
            // Stop audio visualization
            stopAudioVisualization();
            
            // Close audio context
            if (audioContext && audioContext.state !== 'closed') {
                audioContext.close();
                audioContext = null;
            }
            
            // Stop audio stream
            if (audioStream) {
                audioStream.getTracks().forEach(track => track.stop());
                audioStream = null;
            }
            
            // Update UI
            isVoiceMode = false;
            elements.voiceToggle.classList.remove('active');
            elements.voiceToggle.textContent = 'üé§';
            elements.voiceToggle.title = 'Voice Input';
            elements.audioVisualizer.classList.remove('active');
            elements.messageInput.placeholder = 'Type your message here... (or click the mic to speak)';
        }

        function startAudioVisualization() {
            if (!audioAnalyzer || visualizerInterval) return;
            
            visualizerInterval = setInterval(() => {
                if (!audioAnalyzer || !isVoiceMode) return;
                
                const bufferLength = audioAnalyzer.frequencyBinCount;
                const dataArray = new Uint8Array(bufferLength);
                audioAnalyzer.getByteFrequencyData(dataArray);
                
                const bars = elements.audioBars.children;
                const step = Math.floor(bufferLength / bars.length);
                
                for (let i = 0; i < bars.length; i++) {
                    const value = dataArray[i * step];
                    const height = (value / 255) * 50 + 2; // Scale to 2-52px
                    bars[i].style.height = `${height}px`;
                }
            }, 50);
        }

        function stopAudioVisualization() {
            if (visualizerInterval) {
                clearInterval(visualizerInterval);
                visualizerInterval = null;
            }
            
            // Reset all bars
            const bars = elements.audioBars.children;
            for (let bar of bars) {
                bar.style.height = '2px';
            }
        }

        // Audio configuration function (for code-level configuration)
        function configureAudio(newConfig) {
            // Merge new configuration with existing config
            Object.assign(audioConfig, newConfig);
            
            console.log('Audio configuration updated:', audioConfig);
            
            // If we have an active audio worklet, update its configuration
            if (audioWorkletNode && isVoiceMode) {
                audioWorkletNode.port.postMessage({
                    command: 'configure',
                    bufferSizeMs: audioConfig.bufferSizeMs,
                    silenceThreshold: audioConfig.silenceThreshold,
                    maxSilenceMs: audioConfig.maxSilenceMs,
                    adaptiveBuffering: audioConfig.adaptiveBuffering,
                    speechDetectionWindow: audioConfig.speechDetectionWindow
                });
                
                addSystemMessage('Audio configuration updated during recording', 'success');
            }
        }
        
        // Preset configurations for different scenarios
        function useAudioPreset(preset) {
            const presets = {
                'high_quality': {
                    bufferSizeMs: 500,
                    silenceThreshold: 0.005,
                    maxSilenceMs: 750,
                    adaptiveBuffering: true,
                    compressionEnabled: true,
                    logPerformance: true
                },
                'balanced': {
                    bufferSizeMs: 250,
                    silenceThreshold: 0.01,
                    maxSilenceMs: 500,
                    adaptiveBuffering: true,
                    compressionEnabled: true,
                    logPerformance: false
                },
                'low_latency': {
                    bufferSizeMs: 125,
                    silenceThreshold: 0.02,
                    maxSilenceMs: 300,
                    adaptiveBuffering: false,
                    compressionEnabled: true,
                    logPerformance: false
                },
                'noisy_environment': {
                    bufferSizeMs: 350,
                    silenceThreshold: 0.05,
                    maxSilenceMs: 600,
                    adaptiveBuffering: true,
                    compressionEnabled: true,
                    logPerformance: true
                }
            };
            
            if (presets[preset]) {
                configureAudio(presets[preset]);
                console.log('Applied audio preset: ' + preset);
            } else {
                console.warn('Unknown audio preset: ' + preset);
                console.log('Available presets:', Object.keys(presets));
            }
        }

        function clearChat() {
            // Clear current agent's chat history
            chatHistories[currentAgent] = [];
            
            // Clear the display
            elements.chatMessages.innerHTML = '';
            
            // Update message count after clearing
            updateMessageCount();
            
            // Add welcome message for the current agent
            const welcomeMessages = {
                'single': 'Welcome to Single Agent! I\'m a general-purpose assistant ready to help.',
                'multi': 'Welcome to Multi Agent! I\'ll intelligently route your requests to specialized agents.',
                'handsoff': 'Welcome to Hands-Off Agent! I can work autonomously on complex tasks.'
            };
            
            addSystemMessage(welcomeMessages[currentAgent], 'success');
        }

        function updateSpeechLanguage() {
            if (websocket && websocket.readyState === WebSocket.OPEN) {
                const language = elements.languageSelect.value;
                websocket.send(JSON.stringify({
                    type: 'config',
                    language: language,
                    source: 'webrtc'
                }));
                addSystemMessage(`Language changed to: ${language}`, 'success');
            }
        }
    </script>
</body>
</html>
